{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e5afa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b3b9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNER:\n",
    "    def __init__(self,text,java_path,classifier,path_to_jar):\n",
    "        self.text=text\n",
    "        #set java path in environment variables\n",
    "        self.java_path=java_path\n",
    "        os.environ['JAVAHOME']=java_path\n",
    "        #load stanford NER\n",
    "        self.sn=StanfordNERTagger(classifier,path_to_jar=path_to_jar)\n",
    "        \n",
    "        \n",
    "    def document_to_sentence(self,document):\n",
    "        \"\"\"\n",
    "        将document按句子分割为sentences\n",
    "        \"\"\"\n",
    "        document=re.sub('\\n',' ',document)#把document字符串中的换行符替换为空格\n",
    "        if isinstance(document,str):\n",
    "            document=document\n",
    "        else:\n",
    "            raise ValueError('Document is not string!')\n",
    "        document=document.strip()#删除开头结尾处字符,默认删除空白符(包括'\\n',''\\r',''\\t','')\n",
    "        sentences=nltk.sent_tokenize(document)#按句子分割\n",
    "        sentences=[sentence.strip() for sentence in sentences]\n",
    "        return sentences\n",
    "    \n",
    "    def sentence_to_tokenized(self,sentences):\n",
    "        \"\"\"\n",
    "        将senteces按词分割为tokenized_sentences\n",
    "        \"\"\"\n",
    "        tokenized_sentences=[nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "        return tokenized_sentences\n",
    "    \n",
    "    def tokenized_to_annotated(self,tokenized_sentences):\n",
    "        \"\"\"\n",
    "        tag sentences\n",
    "        \"\"\"\n",
    "        ne_annotated_sentences=[self.sn.tag(sent) for sent in tokenized_sentences]\n",
    "        return ne_annotated_sentences\n",
    "    \n",
    "    def extract_named_entities(self,ne_annotated_sentences):\n",
    "        #extract named entities\n",
    "        named_entities=[]\n",
    "        for sentence in ne_annotated_sentences:\n",
    "            temp_entity_name=''\n",
    "            temp_named_entity=None\n",
    "            for term,tag in sentence:\n",
    "                if tag != 'O':\n",
    "                    temp_entity_name=' '.join([temp_entity_name,term]).strip()\n",
    "                    temp_named_entity=(temp_entity_name,tag)\n",
    "                else:\n",
    "                    if temp_named_entity:\n",
    "                        named_entities.append(temp_named_entity)\n",
    "                        temp_entity_name=''\n",
    "                        temp_named_entity=None\n",
    "        #get unique named entities\n",
    "        named_entitie=list(set(named_entities))\n",
    "        #store named entities in a data frame\n",
    "        entity_frame=pd.DataFrame(named_entities,columns=['Entity Name','Entity Type'])\n",
    "        return entity_frame\n",
    "    \n",
    "    def sparse(self):\n",
    "        \"\"\"\n",
    "        NER主函数\n",
    "        \"\"\"\n",
    "        sentences=self.document_to_sentence(self.text)\n",
    "        tokenized_sentences=self.sentence_to_tokenized(sentences)\n",
    "        ne_annotated_sentences=self.tokenized_to_annotated(tokenized_sentences)\n",
    "        res=self.extract_named_entities(ne_annotated_sentences)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ef91fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Entity Name   Entity Type\n",
      "0                      FIFA  ORGANIZATION\n",
      "1                      1904          DATE\n",
      "2                   Belgium      LOCATION\n",
      "3                   Denmark      LOCATION\n",
      "4                    France      LOCATION\n",
      "5                   Germany      LOCATION\n",
      "6           the Netherlands      LOCATION\n",
      "7                     Spain      LOCATION\n",
      "8                    Sweden      LOCATION\n",
      "9               Switzerland      LOCATION\n",
      "10                   Zürich      LOCATION\n",
      "11                   Africa      LOCATION\n",
      "12                     Asia      LOCATION\n",
      "13                   Europe      LOCATION\n",
      "14  North & Central America  ORGANIZATION\n",
      "15                Caribbean      LOCATION\n",
      "16                  Oceania      LOCATION\n",
      "17            South America      LOCATION\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "FIFA was founded in 1904 to oversee international competition among the national associations of Belgium, \n",
    "Denmark, France, Germany, the Netherlands, Spain, Sweden, and Switzerland. Headquartered in Zürich, its \n",
    "membership now comprises 211 national associations. Member countries must each also be members of one of \n",
    "the six regional confederations into which the world is divided: Africa, Asia, Europe, North & Central America \n",
    "and the Caribbean, Oceania, and South America.\n",
    "\"\"\"\n",
    "java_path=r'D:\\Java\\jdk-11.0.12\\bin\\java.exe'\n",
    "classifier='D:/stanford-ner-2020-11-17/classifiers/english.muc.7class.distsim.crf.ser.gz'\n",
    "path_to_jar='D:/stanford-ner-2020-11-17/stanford-ner.jar'\n",
    "sner=SNER(text,java_path,classifier,path_to_jar)\n",
    "res=sner.sparse()\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
